#!/bin/sh

YTFZF_VERSION="2.0_alpha"

# Scraping: query -> video json
# User Interface: video json -> user selection -> ID
# Player: ID -> video player

# Utility functions {{{
dep_check() {
	command -v "$1" > /dev/null 2>&1
}

function_exists () {
	type "$1" > /dev/null 2>&1
}

print_info () {
	# information goes to stdout ( does not disturb show_link_only )
	printf "$1" >&2
}

#rev (the utility) is not posix compliant, use this function instead
rev () {
    #for each line in stdin
    while IFS= read line; do
	#clear the reverse string
	rev=
	#while line is not empty
	while [ -n "$line" ]; do
	    #rev = next_char + rev
	    rev=$(printf '%.1s' "$line")$rev
	    #remove next_char
	    line=${line#?}
	done
	#print reversed line
	printf "%s\n" "$rev"
    done
}

# }}}

# Global Variables and Start Up {{{
: ${useragent='Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.152 Safari/537.36'}
: ${cache_dir=$HOME/.cache/ytfzf}
: ${thumb_dir=$cache_dir/thumb}
[ -d "$cache_dir" ] || mkdir -p "$cache_dir"

# menu options
#the menu to use instead of fzf when -D is specified
function_exists "external_menu" || external_menu () {
	dmenu -i -l 30 -p Search: 
}
#number of columns (characters on a line) the external menu can have
: ${external_menu_len=220}

# Players
function_exists "video_player" || video_player () {
	mpv "$@"
}
function_exists "video_player_format" || video_player_format () {
	mpv --ytdl-format="$video_pref" "$@"
}
function_exists "audio_player" || audio_player () {
       	mpv --no-video "$@"
}
function_exists "downloader" || downloader () {
	case $is_audio_only in
	    0) youtube-dl -f "${video_pref:-best}" "$@"	;;
	    1) youtube-dl -x "$@" ;;
	esac
}

# format options
: ${is_audio_only=0}
: ${is_download=0}
: ${video_pref=}
: ${show_link_only=0}

: ${show_thumbnails=0}
: ${is_ext_menu=0}

# scrape
: ${scrape=youtube}
: ${sub_link_count=10}

tab_space=$(printf '\t')
gap_space="                                                                   "

# colors {{{
c_red="\033[1;31m"
c_green="\033[1;32m"
c_yellow="\033[1;33m"
c_blue="\033[1;34m"
c_magenta="\033[1;35m"
c_cyan="\033[1;36m"
c_reset="\033[0m"
#}}}

# }}}

usage () {
	printf "%s" \
"Usage: ytfzf [OPTIONS...] <search-query>
    OPTIONS:
	-h			Show this help text
	-d			Download the selected video(s)
	-m			Only play audio
	-L			Show the link of selected video(s)
	-c			The scraper to use,
				Builtin scrapers:
				    youtube, youtube-trending, youtube-subscriptions,
				    peertube, odysee/lbry
	-t			Show thumbnails
	-D			Use an external menu
"
}

# Scraping {{{
# * a scraper function takes a search query as $1 and returns video json to file $2
# * argument 3 and above are undefined and can be used for filters
# * return codes:
#            1 : no response from site

# Json keys:
#	Needed:
#	ID url title
#	Optional:
#	thumbs channel duration views date description


## Youtube {{{
_youtube_get_request () {
	_base_url=$1
	_query=$2
	_sp=$3
	# Get search query from youtube
	curl "$_base_url" -s -L \
	  -G --data-urlencode "search_query=$_query" \
	  --data-urlencode "sp=$_sp" \
	  -H 'Authority: www.youtube.com' \
	  -H "User-Agent: $useragent" \
	  -H 'Accept-Language: en-US,en;q=0.9' \
	  --compressed
}
_youtube_get_json () {
	# Separates the json embedded in the youtube html page
	# * removes the content after ytInitialData
	# * removes all newlines and trims the json out
	sed -n '/var *ytInitialData/,$p' |
		tr -d '\n' |
		sed -E ' s_^.*var ytInitialData ?=__ ; s_;</script>.*__ ;'
}

# Search Related functions {{{
_youtube_search_json_playlist () {
	jq '[ .contents|
	..|.playlistRenderer? |
	select(. !=null) |
		{
			ID: .playlistId,
			url: "https://www.youtube.com/playlist?list=\(.playlistId)",
			title: "[Playlist] \(.title.simpleText)",
			thumbs: .thumbnails[0].thumbnails[0].url|sub("\\?.*";""),
			channel: .longBylineText.runs[0].text,
			duration: "\(.videoCount) videos",
			views: "playlist",
			date: "playlist"
		}
	]'
}
_youtube_search_json_videos () {
	jq '[ .contents| ..|.videoRenderer? | select(. !=null) |
		{
			ID: .videoId,
			url: "https://www.youtube.com/watch?v=\(.videoId)",
			title: .title.runs[0].text,
			channel: .longBylineText.runs[0].text,
			thumbs: .thumbnail.thumbnails[0].url|sub("\\?.*";""),
			duration:.lengthText.simpleText,
			views: .shortViewCountText.simpleText,
			date: .publishedTimeText.simpleText,
			description: .detailedMetadataSnippets[0].snippetText.runs[0].text
		}
	]'
}
_youtube_get_sp_filter () {

	if [ -n "$sp" ]; then
		#youtube puts in %253d one ore more times in the filter id, it doesn't seem useful, so we are removing it if it's in the filter
		sp=${sp%%%*}
		return
	fi

	sort_by_filter=$1
	upload_date_filter=$2

	#filter_id is a variable that keeps changing throught this function
	filter_id=

	#sp is the final filter id that is used in the search query
	sp=

	#the way youtube uses these has a pattern, for example
	    #in the sort_by_filter the only difference is the 3rd character, I just don't know how to use this information efficiently
	case $sort_by_filter in
		upload-date) filter_id="CAISBAgAEAE" ;;
		view-count) filter_id="CAMSBAgAEAE" ;;
		rating) filter_id="CAESBAgAEAE" ;;
	esac

	#another example is sort by filter + upload date filter only changes one character as well
	if [ -n "$filter_id" ]; then
		#gets the character in the filter_id that needs to be replaced if upload_date_filter is also given
		upload_date_character=$(printf "%s" "$filter_id" | awk '{print substr($1, 8, 1)}')
	fi

	#For each of these, if upload_date_character is unset, the filter_id should be the normal filter
	#Otherwise set the upload_date_character to the right upload_date_character
	case $upload_date_filter in
		last-hour)
			[ -z "$upload_date_character" ] && filter_id="EgQIARAB" || upload_date_character="B" ;;
		today)
			[ -z "$upload_date_character" ] && filter_id="EgQIAhAB" || upload_date_character="C" ;;
		this-week)
			[ -z "$upload_date_character" ] && filter_id="EgQIAxAB" || upload_date_character="D" ;;
		this-month)
			[ -z "$upload_date_character" ] && filter_id="EgQIBBAB" || upload_date_character="E" ;;
		this-year)
			[ -z "$upload_date_character" ] && filter_id="EgQIBRAB" || upload_date_character="F" ;;
	esac

	#if upload_date_character isn't empty, set sp to upload_date filter + sort_by filter
	if [ -n "$upload_date_character" ]; then
		#replaces the 8th character in the filter_id with the appropriate character
		#the 8th character specifies the upload_date_filter
		sp=$(printf "%s" "$filter_id" | sed 's/\(.\{7\}\)./\1'"$upload_date_character"'/')
	#otherwise set it to the filter_id
	else
		sp=$filter_id
	fi
	unset upload_date_character filter_id
}
#}}}

# Channel Related functions {{{
_youtube_channel_name () {
	# takes channel page html (stdin) and returns the channel name
	grep -o '<title>.*</title>' |
		sed \
		-e 's/ - YouTube//' \
		-e 's/<\/\?title>//g' \
		-e "s/&apos;/'/g" \
		-e "s/&#39;/'/g" \
		-e "s/&quot;/\"/g" \
		-e "s/&#34;/\"/g" \
		-e "s/&amp;/\&/g" \
		-e "s/&#38;/\&/g"
}
_youtube_channel_json () {
	channel_name=$1
	jq '[ .contents | ..|.gridVideoRenderer? | select(. !=null) |
	    {
	    	ID: .videoId,
			url: "https://www.youtube.com/watch?v=\(.videoId)",
	    	title: .title.simpleText,
	    	channel: "'"$channel_name"'",
	    	thumbs: .thumbnail.thumbnails[0].url|sub("\\?.*";""),
	    	duration:.thumbnailOverlays[0].thumbnailOverlayTimeStatusRenderer.text.simpleText,
	    	views: .shortViewCountText.simpleText,
	    	date: .publishedTimeText.simpleText,
	    }
	]'
}
#}}}

scrape_youtube () {
	page_query=$1
	output_json_file=$2
	pagetype=$3
	
	_tmp_html=$(mktemp)
	_tmp_json=$(mktemp)

	case $pagetype in
		''|search)
			# TODO: sp
			_youtube_get_request "https://www.youtube.com/results" "$page_query" > "$_tmp_html"

			_youtube_get_json < "$_tmp_html" > "$_tmp_json"

			{
				_youtube_search_json_videos < "$_tmp_json"
				_youtube_search_json_playlist < "$_tmp_json"
			} > "$output_json_file"
			;;
		trending)
			trending_tab=$query

			case $trending_tab in
				 music) tab_data="4gINGgt5dG1hX2NoYXJ0cw%3D%3D" ;;
				gaming) tab_data="4gIcGhpnYW1pbmdfY29ycHVzX21vc3RfcG9wdWxhcg%3D%3D" ;;
				movies) tab_data="4gIKGgh0cmFpbGVycw%3D%3D" ;;
			esac

			_youtube_get_request "https://www.youtube.com/feed/trending?bp=$tab_data" "" "" > "$_tmp_html"

			_youtube_get_json < "$_tmp_html" > "$_tmp_json"
			{
				_youtube_search_json_videos < "$_tmp_json"
				_youtube_search_json_playlist < "$_tmp_json"
			} > "$output_json_file"
			;;
		channel)
			channel_url=$page_query

			# Converting channel title page url to channel video url
			case $channel_url in
				*featured)
				channel_url=${channel_url%featured}videos
					;;
			esac

			_youtube_get_request "$channel_url" "" "" > "$_tmp_html"
			_youtube_get_json < "$_tmp_html" > "$_tmp_json"

			channel_name=$(_youtube_channel_name < "$_tmp_html" )
			_youtube_channel_json "$channel_name" < "$_tmp_json"  > "$output_json_file"
			;;
	esac

	rm "$_tmp_html" "$_tmp_json"
}
## }}}

## Peertube {{{
scrape_peertube () {
	page_query=$1
	output_json_file=$2

	_tmp_json=$(mktemp)

	#gets a list of videos
	curl -s "https://sepiasearch.org/api/v1/search/videos" \
	  -G --data-urlencode "search=$1" > "$_tmp_json"

	jq '[ .data | .[] |
			{
				ID: .uuid,
				url: .url,
				title: .name,
				channel: .channel.displayName,
				thumbs: .thumbnailUrl,
				duration: .duration,
				views: .views,
				date: .publishedAt
			}
		]' < "$_tmp_json" > "$output_json_file"

	rm "$_tmp_json"
}
## }}}

## Odysee {{{
scrape_odysee () {

	page_query=$1
	output_json_file=$2

	_tmp_json=$(mktemp)

	# TODO: filters
	curl \
	    -s "https://lighthouse.lbry.com/search" \
	    -G --data-urlencode "s=$page_query" \
	    --data-urlencode "mediaType=video,audio" \
	    --data-urlencode "include=channel,title,thumbnail_url,duration,cq_created_at,description" \
	    --data-urlencode "size=$odysee_video_search_count" > "$_tmp_json"

	jq '[ .[] | 
	    {
			ID: .claimId,
			title: .title,
			url: "https://www.odysee.com/\(.channel)/\(.name)",
			channel: .channel,
			thumbs: .thumbnail_url,
			duration: .duration,
			views: .view_cnt,
			date: .cq_created_at
	    }
	]' < "$_tmp_json" > "$output_json_file" 
	# TODO:  error handling 2 character

	rm "$_tmp_json"
}
## }}}


# }}}

# TODO: sorting
sort_video_data_fn () {

	if [ $is_sort -eq 1 ]; then
		while IFS= read -r line
		do
			id=${line##*|}
			date=$(printf "%s" "$line" | rev | cut -f2 -d "|" | rev )
			date=${date#*Streamed} # youtube_specific
			
			#run the key function to get the value to sort by
			printf "%s\t%s\n" "$(date -d "$date" '+%s')" "$line"
		done | sort -nr | cut -f2-
	fi
}

# User Interface {{{
# Takes video json file as $1 and returns the selected video IDs to file $2
video_info_text () {
	printf "%-${title_len}.${title_len}s\t" "$title"
	printf "%-${channel_len}.${channel_len}s\t" "$channel"
	printf "%-${dur_len}.${dur_len}s\t" "$duration"
	printf "%-${view_len}.${view_len}s\t" "$views"
	printf "%-${date_len}.${date_len}s\t" "$date"
	printf "%s" "$shorturl"
	printf "\n"
}

thumbnail_video_info_text () {
	printf "\n ${c_cyan}%s" "$title"
	printf "\n ${c_blue}Channel  ${c_green}%s" "$channel"
	printf "\n ${c_blue}Duration ${c_yellow}%s" "$duration"
	printf "\n ${c_blue}Views    ${c_magenta}%s" "$views"
	printf "\n ${c_blue}Date     ${c_cyan}%s" "$date"
	printf "\n ${c_blue}Description ${c_reset}: %s" "$description"
}

# Text interface {{{
interface_text () {
	video_json_file=$1
	selected_id_file=$2

	# video_info_text can be set in the conf.sh, if set it will be preferred over the default given below
	TTY_COLS=$(tput cols)
	title_len=$((TTY_COLS/2))
	channel_len=$((TTY_COLS/5))
	dur_len=7
	view_len=10
	date_len=100

	jq -r '.[]|"\(.title)\t|\(.channel)\t|\(.duration)\t|\(.views)\t|\(.date)\t|\(.ID)"' < "$video_json_file" |
		while IFS=$tab_space read title channel duration views date shorturl
		do
			video_info_text
		done |  
		column -t -s "$tab_space" |
		fzf -m --tabstop=1 --layout=reverse |
		rev | cut -f1 -d "|" | rev > "$selected_id_file"
}
#}}}

# External interface {{{
interface_external () {
	video_json_file=$1
	selected_id_file=$2

	# video_info_text can be set in the conf.sh, if set it will be preferred over the default given below
	TTY_COLS=$external_menu_len
	title_len=$((TTY_COLS/2))
	channel_len=$((TTY_COLS/5))
	dur_len=7
	view_len=10
	date_len=100


	jq -r '.[]|"\(.title)\t|\(.channel)\t|\(.duration)\t|\(.views)\t|\(.date)\t|\(.ID)"' < "$video_json_file" |
		while IFS=$tab_space read title channel duration views date shorturl
		do
			video_info_text
		done | tr -d "$tab_space" | 
		external_menu |
		rev | cut -f1 -d "|" | rev > "$selected_id_file"
}
#}}}

# Thumbnail Interface {{{

# Image preview {{{
preview_start () {
	thumbnail_viewer=$1
	case $thumbnail_viewer in
		ueberzug)
			# starts uberzug to this fifo
			export UEBERZUG_FIFO="/tmp/ytfzf-ueberzug-fifo"
			rm -f "$UEBERZUG_FIFO"
			mkfifo "$UEBERZUG_FIFO"
			ueberzug layer --parser simple < "$UEBERZUG_FIFO" 2>/dev/null &
			exec 3> "$UEBERZUG_FIFO" # to keep the fifo open
			;;
	esac
}
preview_stop () {
	thumbnail_viewer=$1
	case $thumbnail_viewer in
		ueberzug)
			exec 3>&- # close file descriptor 3, closing ueberzug
			;;
	esac
}
preview_display_image () {
	thumbnail_viewer=$1
	id=$2
	case $thumbnail_viewer in
		ueberzug)
			printf '%s\t' \
				'action' 'add' \
				'identifier' 'ytfzf' \
				'path' "$thumb_dir/${id}.jpg" \
				'x' '2' \
				'y' '10' \
				'scaler' 'fit_contain' \
				'width' "$((FZF_PREVIEW_COLUMNS))" > "$UEBERZUG_FIFO"
			printf '%s\t%s\n' \
				'height' "$((FZF_PREVIEW_LINES-10))" > "$UEBERZUG_FIFO"
			;;
	esac
}
#}}}

preview_img () {
	# This function is common to every thumbnail viewer
	thumbnail_viewer=$1
	line=$2
	video_json_file=$3
	id=${line##*|}

	IFS=$tab_space read -r title channel duration views date description <<-EOF
	$(
		jq -r '.[]|select( .ID == "'"$id"'")|
			[.title,.channel,.duration,.views,.date,.description]|
			@tsv' < "$video_json_file"
	)
	EOF

	thumbnail_video_info_text "$id"
	preview_display_image "$thumbnail_viewer" "$id"
	exit
}

interface_thumbnails () {
	# Takes video json file and downloads the thumnails as ${ID}.png to thumb_dir
	video_json_file=$1
	selected_id_file=$2
	mkdir -p "$thumb_dir"

	# Dowload thumbnails, 
	{
		print_info 'Fetching thumbnails...\n'
		curl_config_file=$(mktemp)
		jq -r '.[]|"
			url = \"\(.thumbs)\"
			output = \"'"$thumb_dir"'/\(.ID).jpg\""' \
				< "$video_json_file" > "$curl_config_file"
			# curl version > 7.66.0 ( else remove -Z )
			curl -Z -K "$curl_config_file" || curl -K "$curl_config_file"
		rm "$curl_config_file"
	}
	
	thumbnail_viewer=ueberzug

	preview_start "$thumbnail_viewer"

	# ytfzf -U preview_img ueberzug {} "$video_json_file"
	jq -r '.[]|[.title,"'"$gap_space"'|"+.date,"|"+.ID]|@tsv' < "$video_json_file" |
	fzf -m \
	--preview "sh $0 -U preview_img '"$thumbnail_viewer"' {} '"$video_json_file"'" \
	--preview-window "left:50%:wrap" --layout=reverse |
	rev | cut -f1 -d "|" | rev > "$selected_id_file"

	preview_stop "$thumbnail_viewer"

	rm -r "$thumb_dir"
}
#}}}

#}}}

# Player {{{
open_player () {
	# isaudio, isdownload, video_pref
	if [ $show_link_only -eq 1 ]; then
		printf '%s\n' "$@"
		return
	fi

	if [ $is_download -eq 1 ]; then
		print_info "Downloading $# video(s)\n"
		[ -n "$video_pref" ] && video_pref="best"
		downloader "$@"
		return
	fi

	print_info "Playing $# videos\n"

	[ -n "$video_pref" ] && { video_player_format "$@"; exit; }
	[ $is_audio_only -eq 1 ] && video_pref="bestaudio" && { audio_player "$@"; exit; }
	video_player "$@"; exit
}
player () {
	# takes the json data file as $1 and the selected id file as $2
	video_json_file=$1
	id_file=$2
	options=$3

	url_file=$(mktemp)
	{
		# get urls from the ids
		urls=
		while IFS= read id; do
			urls=${urls}' '$(jq -r '.[]|select(.ID == "'"$id"'").url' < "$video_json_file")
		done < "$id_file"
		[ -z "$urls" ] && exit
	}

	set -f
	set -- $urls
	open_player "$@"
}
#}}}

# Options {{{
while getopts 'hdmfc:tLTDU' OPT; do
	case $OPT in
		h) usage; exit ;;
		d) is_download=1 ;;
		m) is_audio_only=1 ;;
		L) show_link_only=1 ;;
		f) # TODO
			: ;;
		c) scrape=$OPTARG ;;
		t) show_thumbnails=1 ;;
		D) is_ext_menu=1 ;;
		U) # Reserved for internal use
			shift
			case $1 in
				preview_img)
					shift
					preview_img "$@"
					;;
			esac
			;;
	esac
done
shift $((OPTIND-1))
#}}}

# Main {{{
json_file=$(mktemp)
id_file=$(mktemp)
print_info 'Scraping site...\n'

case $scrape in
	youtube) scrape_youtube  "$*" "$json_file" ;;
	youtube-trending) scrape_youtube  "" "$json_file" "trending";;
	youtube-subscriptions)#{{{
		subscription_file=~/.config/ytfzf/subscriptions

		if ! [ -f "$subscription_file" ]; then
			print_info "subcription file doesn't exist\n"
			exit 1
		fi

		while IFS= read channel_url || [ -n "$channel_url" ] ; do
			{
				_tmp_subfile=$(mktemp)
				scrape_youtube "$channel_url" "$_tmp_subfile" "channel" < /dev/null
				jq '.[0:'"$sub_link_count"']' < "$_tmp_subfile" >> "$json_file"
				rm "$_tmp_subfile"
			} &
			sleep 0.01
		done <<-EOF
		$(sed \
		-e "s/#.*//" \
		-e "/^[[:space:]]*$/d" \
		-e "s/[[:space:]]*//g" \
		"$subscription_file" )
		EOF
		wait
		;;#}}}
	peertube) scrape_peertube "$*" "$json_file" ;;
	odysee|lbry) scrape_odysee "$*" "$json_file" ;;
	*) print_info 'invalid channel\n'; exit 1 ;;
esac

case 1 in
	"$show_thumbnails") interface_thumbnails "$json_file" "$id_file" ;;
	    "$is_ext_menu") interface_external   "$json_file" "$id_file" ;;
	                 1) interface_text       "$json_file" "$id_file" ;;
esac

player "$json_file" "$id_file"
#}}}

# Clean up {{{
rm "$json_file"
rm "$id_file"
#}}}
# vim:foldmethod=marker
